# -*- coding: utf-8 -*-
"""functions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1--J4W9l49AMloj4l58h29Us7qhTPRkFw
"""

def analisis_descriptivo(df):
  # Agregar nombres a las columnas
  df.columns = ['Open_time','Open','High','Low','Close',
                'Volume','Close_time','Quote_asset_volume',
                'Number_of_trades','Taker_buy_base_asset_volume',
                'Taker_buy_quote_asset_volume','Ignore','Response']

  # Mostrar información
  print(df.info())

  # Mostrar estadística descriptiva
  print(df.describe())

  # Convertir las columnas de 'Open_time' y 'Close_time' a formato de fecha y hora
#  df['Open_time'] = pd.to_datetime(df['Open_time'], unit='ms', origin='unix')
#  df['Close_time'] = pd.to_datetime(df['Close_time'], unit='ms', origin='unix')

  # Mostrar el dataframe
  print(df.head())

  return df

def analisis_exploratorio(df):
    # Imprimir histogramas de todas las variables
    df.hist()
    plt.show()

    # Calcular simetría de las variables
    simetria = df.skew()
    print("Simetría de las variables:")
    print(simetria)

    # Calcular curtosis de las variables
    curtosis = df.kurt()
    print("\nCurtosis de las variables:")
    print(curtosis)

    # Dividir el tiempo en día de la semana, hora del día y mes
    df['Open_time'] = pd.to_datetime(df['Open_time'], unit='ms', origin='unix')
    df.set_index('Open_time', inplace=True)
    df['day_of_week'] = df.index.dayofweek
    df['hour_of_day'] = df.index.hour
    df['month'] = df.index.month

    # Histograma de día de la semana
    sns.countplot(x='day_of_week', data=df)
    plt.xlabel('Día de la Semana')
    plt.ylabel('Frecuencia')
    plt.show()

    # Histograma de hora del día
    sns.countplot(x='hour_of_day', data=df)
    plt.xlabel('Hora del Día')
    plt.ylabel('Frecuencia')
    plt.show()

    # Histograma de mes
    sns.countplot(x='month', data=df)
    plt.xlabel('Mes')
    plt.ylabel('Frecuencia')
    plt.show()

    # Calcular valores atípicos
    q1 = df.quantile(0.25)
    q3 = df.quantile(0.75)
    iqr = q3 - q1
    print("\nValores atípicos (IQR):")
    print(iqr)

    # Ajuste de distribución de probabilidad empírica

    # Boxplot de precios
    sns.boxplot(data=df[['Open', 'High', 'Low', 'Close']])
    plt.show()

    # Boxplot de volumen y número de operaciones
    sns.boxplot(data=df[['Volume', 'Number_of_trades']])
    plt.show()

    # Boxplot de volumen y volumen de compra
    sns.boxplot(data=df[['Quote_asset_volume', 'Taker_buy_quote_asset_volume']])
    plt.show()

    # Boxplot de volumen de compra de activos base
    sns.boxplot(data=df['Taker_buy_base_asset_volume'])
    plt.show()

def ajuste_distribuciones_empiricas(df, columnas):
    # Iterar sobre las columnas especificadas
    for columna in columnas:
        datos = df[columna]

        # Obtener los parámetros de ajuste para varias distribuciones
        distribuciones = ['gamma', 'expon', 'lognorm', 'beta', 'norm']
        resultados_evaluacion = []
        mejor_distribucion = None
        mejor_parametros = None
        mejor_sse = float('inf')

        for distribucion in distribuciones:
            # Ajustar la distribución a los datos
            distribucion_actual = getattr(stats, distribucion)
            parametros = distribucion_actual.fit(datos)

            # Calcular el error cuadrático medio (SSE) para evaluar el ajuste
            sse = sum((distribucion_actual.pdf(datos, *parametros) - datos)**2)

            # Calcular el AIC y el BIC
            n = len(datos)
            k = len(parametros)
            aic = n * np.log(sse / n) + 2 * k
            bic = n * np.log(sse / n) + k * np.log(n)

            resultados_evaluacion.append({
                'Distribución': distribucion,
                'SSE': sse,
                'AIC': aic,
                'BIC': bic
            })
            # Actualizar la mejor distribución si encontramos un SSE más bajo
            if sse < mejor_sse:
                mejor_distribucion = distribucion_actual
                mejor_parametros = parametros
                mejor_sse = sse

        df_resultados = pd.DataFrame(resultados_evaluacion)
        # Configuración del estilo de la gráfica
        sns.set(style="whitegrid")

        # Creación de la gráfica con histograma y distribución mejor ajustada
        plt.figure(figsize=(8, 6))
        sns.histplot(datos, bins=30, kde=True, color='skyblue', label='Datos', stat='density')
        x = np.linspace(datos.min(), datos.max(), 100)
        pdf = mejor_distribucion.pdf(x, *mejor_parametros)
        plt.plot(x, pdf, 'r-', linewidth=2, label='Distribución Mejor Ajustada')
        plt.xlabel(columna)
        plt.ylabel('Densidad de Probabilidad')
        plt.title(f'Ajuste de Distribución a {columna}')
        plt.legend()
        plt.show()

        print(df_resultados)

def calcular_caracteristicas_lineales(df):
    # Calcular características lineales
    df['co'] = df['Close'].shift(-1) - df['Open']
    df['hl'] = df['High'].shift(-1) - df['Low']
    df['ol'] = df['Open'].shift(-1) - df['Low']
    df['ho'] = df['High'].shift(-1) - df['Open']
    df['cov'] = df['co'] / df['Volume']
    df['hlv'] = df['hl'] / df['Volume']

    # Eliminar filas con valores faltantes
    df.dropna(inplace=True)

    # Eliminar columnas no deseadas
    df.drop(['Open', 'High', 'Low', 'Close', 'Ignore'], axis=1, inplace=True)

    # Contar valores faltantes
    missing_values_count = df.isnull().sum()
    print(missing_values_count)

    return df

def calcular_caracteristicas_autorregresivas(df):
    # Calcular características autorregresivas con ventana 2
    df['ma_ol_2'] = df['ol'].rolling(2).mean()
    df['ma_ho_2'] = df['ho'].rolling(2).mean()
    df['ma_hl_2'] = df['hl'].rolling(2).mean()
    df['ma_hlv_2'] = df['hlv'].rolling(2).mean()
    df['ma_cov_2'] = df['cov'].rolling(2).mean()

    df['sd_ol_2'] = df['ol'].rolling(2).std()
    df['sd_ho_2'] = df['ho'].rolling(2).std()
    df['sd_hl_2'] = df['hl'].rolling(2).std()
    df['sd_hlv_2'] = df['hlv'].rolling(2).std()
    df['sd_cov_2'] = df['cov'].rolling(2).std()

    df['lag_vol_2'] = df['Volume'].shift(2)
    df['sum_vol_2'] = df['Volume'].rolling(2).sum()
    df['mean_vol_2'] = df['Volume'].rolling(2).mean()

    # Calcular características autorregresivas con ventana 3
    df['ma_ol_3'] = df['ol'].rolling(3).mean()
    df['ma_ho_3'] = df['ho'].rolling(3).mean()
    df['ma_hl_3'] = df['hl'].rolling(3).mean()
    df['ma_hlv_3'] = df['hlv'].rolling(3).mean()
    df['ma_cov_3'] = df['cov'].rolling(3).mean()

    df['sd_ol_3'] = df['ol'].rolling(3).std()
    df['sd_ho_3'] = df['ho'].rolling(3).std()
    df['sd_hl_3'] = df['hl'].rolling(3).std()
    df['sd_hlv_3'] = df['hlv'].rolling(3).std()
    df['sd_cov_3'] = df['cov'].rolling(3).std()

    df['lag_vol_3'] = df['Volume'].shift(3)
    df['sum_vol_3'] = df['Volume'].rolling(3).sum()
    df['mean_vol_3'] = df['Volume'].rolling(3).mean()

    # Llenar valores faltantes con 0
    df_filled = df.fillna(0)

    # Contar valores faltantes
    missing_values_count = df_filled.isnull().sum()
    print(missing_values_count)

    return df_filled

def preprocesamiento(df):
    # Llenar valores faltantes con 0
    df_filled = df.fillna(0)

    # Crear una copia del DataFrame
    new_df = df_filled.copy()

    # Separar características y variable objetivo
    X = new_df.drop(['Response'], axis=1)
    y = new_df['Response']

    # Reemplazar infinitos con 0
    X[np.isinf(X)] = 0

    # Escalar características
    scaler = preprocessing.MinMaxScaler()
    X_scaled = scaler.fit_transform(X)

    # Dividir datos en conjuntos de entrenamiento y prueba
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=1)

    return X_train, X_test, y_train, y_test

# Ejemplo de uso de la función
# Suponiendo que tienes un DataFrame df
X_train, X_test, y_train, y_test = preprocesamiento(df)
print("Tamaño de X_train:", X_train.shape)
print("Tamaño de X_test:", X_test.shape)
print("Tamaño de y_train:", y_train.shape)
print("Tamaño de y_test:", y_test.shape)

def logistic_regression_model(X_train, X_test, y_train, y_test):
    # Definir el modelo de regresión logística
    lrmodel = LogisticRegression()

    # Definir los hiperparámetros para la búsqueda en cuadrícula
    solvers = ['newton-cg', 'liblinear', 'lbfgs']
    penalty = ['l2', 'l1', 'elasticnet']
    c_values = [100, 10, 1.0, 0.1, 0.01]
    grid = dict(solver=solvers, penalty=penalty, C=c_values)

    # Definir la validación cruzada
    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)

    # Realizar la búsqueda en cuadrícula
    grid_search = GridSearchCV(estimator=lrmodel, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)
    grid_result = grid_search.fit(X_train, y_train)

    # Imprimir los mejores resultados de la búsqueda en cuadrícula
    print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

    # Crear el modelo final con los mejores hiperparámetros encontrados
    logreg = LogisticRegression(**grid_result.best_params_, multi_class='ovr')
    logreg.fit(X_train, y_train)

    # Predecir las etiquetas en el conjunto de prueba
    y_pred_lr = logreg.predict(X_test)

    # Calcular métricas de evaluación
    accuracy_lr = accuracy_score(y_test, y_pred_lr)
    precision_lr = precision_score(y_test, y_pred_lr)
    recall_lr = recall_score(y_test, y_pred_lr)
    f1_score_lr = f1_score(y_test, y_pred_lr)
    conf_matrix = confusion_matrix(y_test, y_pred_lr)

    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(accuracy_lr))
    print('Precision of logistic regression classifier on test set: {:.2f}'.format(precision_lr))
    print('Recall of logistic regression classifier on test set: {:.2f}'.format(recall_lr))
    print('F1 Score of logistic regression classifier on test set: {:.2f}'.format(f1_score_lr))
    print('Confusion Matrix:')
    print(conf_matrix)

    # Calcular la curva ROC y el área bajo la curva (AUC)
    y_scores_lr = logreg.predict_proba(X_test)[:, 1]
    fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_scores_lr)
    auc_roc_lr = roc_auc_score(y_test, y_scores_lr)

    # Graficar la curva ROC
    plt.figure(figsize=(8, 8))
    plt.plot(fpr_lr, tpr_lr, color='blue', lw=2, label=f'AUC = {auc_roc_lr:.2f}')
    plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend(loc="lower right")
    plt.show()

    return logreg, accuracy_lr, precision_lr, recall_lr, f1_score_lr, conf_matrix

def mlp_classifier_model(X_train, X_test, y_train, y_test):
    # Definir el modelo de Perceptrón Multicapa
    mlp = MLPClassifier(random_state=1)

    # Definir los hiperparámetros para la búsqueda en cuadrícula
    param_grid = {
        'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],
        'activation': ['relu', 'tanh'],
        'solver': ['adam', 'sgd'],
        'alpha': [0.0001, 0.001, 0.01],
        'batch_size': [50, 100, 200],
        'learning_rate': ['constant', 'adaptive']
    }

    # Realizar la búsqueda en cuadrícula
    grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring='accuracy')
    grid_search.fit(X_train, y_train)

    # Obtener el mejor modelo y sus hiperparámetros
    best_model = grid_search.best_estimator_
    best_params = grid_search.best_params_

    # Evaluar el mejor modelo en el conjunto de prueba
    y_pred_mlp = best_model.predict(X_test)
    accuracy_mlp = accuracy_score(y_test, y_pred_mlp)
    precision_mlp = precision_score(y_test, y_pred_mlp)
    recall_mlp = recall_score(y_test, y_pred_mlp)
    f1_score_mlp = f1_score(y_test, y_pred_mlp)
    conf_matrix_mlp = confusion_matrix(y_test, y_pred_mlp)

    print('Accuracy of MLP classifier on test set: {:.2f}'.format(accuracy_mlp))
    print('Precision of MLP classifier on test set: {:.2f}'.format(precision_mlp))
    print('Recall of MLP classifier on test set: {:.2f}'.format(recall_mlp))
    print('F1 Score of MLP classifier on test set: {:.2f}'.format(f1_score_mlp))
    print('Confusion Matrix:')
    print(conf_matrix_mlp)

    # Imprimir los mejores hiperparámetros y la precisión en el conjunto de prueba
    print("Mejores hiperparámetros:", best_params)
    print("Precisión en conjunto de prueba:", accuracy_mlp)

    # Calcular la curva ROC y el área bajo la curva (AUC)
    y_scores_mlp = mlp.predict_proba(X_test)[:, 1]
    fpr_mlp, tpr_mlp, thresholdsmlp = roc_curve(y_test, y_scores_mlp)
    auc_roc_mlp = roc_auc_score(y_test, y_scores_mlp)

    # Graficar la curva ROC
    plt.figure(figsize=(8, 8))
    plt.plot(fpr_mlp, tpr_mlp, color='blue', lw=2, label=f'AUC = {auc_roc_mlp:.2f}')
    plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend(loc="lower right")
    plt.show()

    # Retornar el mejor modelo, su precisión y las predicciones
    return best_model, accuracy_mlp, y_pred_mlp