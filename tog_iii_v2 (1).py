# -*- coding: utf-8 -*-
"""TOG-III V2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16cGQG7AN-eBJ3iPF3gucYwc9u7b3G0Yh

# Montaje Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Librerías

## Instalación de Librerías
"""

!pip install scikeras

#!pip install keras==2.12.0
#!pip uninstall tensorflow
#!pip install tensorflow==2.12.0

#!pip uninstall tensorflow
#!pip install tensorflow --ignore-installed

"""## Importación de Librerías"""

import pandas as pd
import numpy as np
from datetime import datetime
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from matplotlib.colors import ListedColormap
import matplotlib.patches as mpatches
import tensorflow as tf
from scikeras.wrappers import KerasClassifier
from sklearn.model_selection import GridSearchCV
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras.constraints import MaxNorm
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import VarianceThreshold
from tensorflow.keras.utils import plot_model
from tensorflow.keras.optimizers import SGD
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, precision_score, recall_score, auc,roc_curve, roc_auc_score
from sklearn.metrics import f1_score
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.inspection import permutation_importance
from scipy.stats import shapiro
from scipy.stats import norm, lognorm, gamma, beta
from scipy.optimize import minimize
from sklearn.metrics import mean_squared_error, r2_score
import scipy.stats
import plotly.graph_objects as go
import statsmodels.api as sm
from scipy import stats
from sklearn.neural_network import MLPClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import validation_curve

"""# Datos

## Importación de Datos
"""

ruta = '/content/drive/MyDrive/TOG/IDI III/Datos/'
df = pd.read_excel(ruta+"datos_klines.xlsx")

"""## Visualización y Descripción de 'data'"""

df.head()

df.columns = ['Open_time','Open','High','Low','Close',
                'Volume','Close_time','Quote_asset_volume',
                'Number_of_trades','Taker_buy_base_asset_volume',
                'Taker_buy_quote_asset_volume','Ignore','Response']

df.head()

"""Información de 'data'"""

df.info()

df.describe()

"""## Conversión 'unix'"""

df['Open_time'] = pd.to_datetime(df['Open_time'], unit='ms', origin='unix')
df['Close_time'] = pd.to_datetime(df['Close_time'], unit='ms',origin='unix')

df.head()

df.info()

"""## Análisis Exploratorio

Definición de los parámetros de los gráficos
"""

plt.rcParams.update({'font.size': 25, 'figure.figsize': (8,6)})
plt.style.use('ggplot')

"""### ¿Cómo están distribuidos los datos?"""

df_hist = df.copy()
df_hist.drop('Open_time', axis = 1)
df_hist.drop('Close_time',axis = 1)

df_hist.drop('Open_time', axis = 1)
df_hist.drop('Close_time',axis = 1)

df_hist.hist()

"""Con la información que se tiene hasta el momento podemos determinar lo siguiente:
- 'Open_time' y 'Close_time' se comportan de la misma manera como pudiera esperarse ya que únicamente son "timestamps"
- 'Open' y 'Close',siendo valores de precio de apertura y cierre por hora, comparten la misma figura de su distribución. Esto es debido a que el precio de Cierre en la hora t será el mismo precio que el de apertura en el tiempo t+1
- Las distribuciones de 'High' y 'Low' son bastante parecidas pero se alcanza a percibir una diferencia alrededor de los valores de 1800 en el eje x
- 3 distribuciones son bastante similares (a simple vista no se encuentran diferencias significativas) 'Number of trades', 'Taker buy base asset volume', 'taker buy quote asset volume'
- La variable 'Ignore' siempre se encuentra en los mismos valores
- La variable de respuesta (subida o bajada de precio) presenta frecuencias similares

### Simetría y Curtosis
"""

df.skew()

df.kurt()

"""### Visualizaciones"""

sns.countplot(x='Response', data=df)
plt.show()

respuestas = df[df['Response'].isin([0,1])]['Response'].value_counts()
respuestas

"""Se puede visualizar variables altamente correlacionadas entre sí.

¿Cómo se comporta los precios a lo largo del tiempo?
"""

fig = go.Figure(data=[go.Candlestick(x=df['Open_time'],
                                     open=df['Open'],
                                     high=df['High'],
                                     low=df['Low'],
                                     close=df['Close'])])
fig.show()

"""¿Cómo cambiaría las visualizaciones si agregaramos variables/características tomando en cuenta la fecha?

Dividiendo 'Open Time'
"""

df.set_index('Open_time', inplace = True)

"""Día de la Semana"""

df['day_of_week'] = df.index.dayofweek

"""Hora del Día"""

df['hour_of_day'] = df.index.hour

"""Mes"""

df['month'] = df.index.month

df.tail()

"""¿Qué día de la semana, hora del día y mes tiene más registros de subida de precios?"""

df_up = df[df['Response'] == 1]
df_down = df[df['Response'] == 0]

sns.countplot(x='day_of_week', data=df_up, order=df_up['day_of_week'].value_counts().index)
#plt.title('Frecuencia de Días de la Semana donde el Precio Sube')
plt.xlabel('Día de la Semana')
plt.ylabel('Frecuencia')
plt.show()

sns.countplot(x='hour_of_day', data=df_up, order=df_up['hour_of_day'].value_counts().index)
#plt.title('Frecuencia de Horas del Día donde el Precio Sube')
plt.xlabel('Hora del Día')
plt.ylabel('Frecuencia')
plt.show()

sns.countplot(x='month', data=df_up, order=df_up['month'].value_counts().index)
#plt.title('Frecuencia de Mes del Año donde el Precio Sube')
plt.xlabel('Mes')
plt.ylabel('Frecuencia')
plt.show()

"""Se aprecia que los días 6 y 4 tienen una frecuencia de subida de precio mayor a los demás días de la semana. Las horas con mayor frecuencia de subida de precio es desde las 17 horas hasta las 23, de acuerdo con los datos utilizados. Por último, se observa que los meses que tienen mayor frecuencia de subida de precios son el mes 1 y el 6."""

conteo_incidencias = df_up.groupby('day_of_week')['Response'].value_counts()
conteo_incidencias

conteo_incidencias2 = df_up.groupby('hour_of_day')['Response'].value_counts()
conteo_incidencias2

conteo_incidencias3 = df_up.groupby('month')['Response'].value_counts()
conteo_incidencias3

"""### Datos Atípicos"""

q1=df.quantile(0.25)
q3=df.quantile(0.75)
iqr=q3-q1
iqr

sns.boxplot(data = df[['Open','High','Low','Close']])

sns.boxplot(data = df[['Volume','Number_of_trades']])

sns.boxplot(data = df[['Quote_asset_volume','Taker_buy_quote_asset_volume']])

sns.boxplot(data = df['Taker_buy_base_asset_volume'])

"""### Ajuste de Distribición de Probabilidad Empírica"""

# Seleccionar la columna 'Taker_buy_quote_asset_volume' del DataFrame
datos_taker_quote = df['Taker_buy_quote_asset_volume']

# Obtener los parámetros de ajuste para varias distribuciones
distribuciones = ['gamma', 'expon', 'lognorm', 'beta', 'norm']
resultados_evaluacion = []
mejor_distribucion = None
mejor_parametros = None
mejor_sse = float('inf')

for distribucion in distribuciones:
    # Ajustar la distribución a los datos
    distribucion_actual = getattr(stats, distribucion)
    parametros = distribucion_actual.fit(datos_taker_quote)

    # Calcular el error cuadrático medio (SSE) para evaluar el ajuste
    sse = sum((distribucion_actual.pdf(datos_taker_quote, *parametros) - datos_taker_quote)**2)

    # Calcular el AIC y el BIC
    n = len(datos_taker_quote)
    k = len(parametros)
    aic = n * np.log(sse / n) + 2 * k
    bic = n * np.log(sse / n) + k * np.log(n)

    resultados_evaluacion.append({
        'Distribución': distribucion,
        'SSE': sse,
        'AIC': aic,
        'BIC': bic
    })
    # Actualizar la mejor distribución si encontramos un SSE más bajo
    if sse < mejor_sse:
        mejor_distribucion = distribucion_actual
        mejor_parametros = parametros
        mejor_sse = sse

df_resultados = pd.DataFrame(resultados_evaluacion)
# Configuración del estilo de la gráfica
sns.set(style="whitegrid")

# Creación de la gráfica con histograma y distribución mejor ajustada
plt.figure(figsize=(8, 6))
sns.histplot(datos_taker_quote, bins=30, kde=True, color='skyblue', label='Datos', stat='density')
x = np.linspace(datos_taker_quote.min(), datos_taker_quote.max(), 100)
pdf = mejor_distribucion.pdf(x, *mejor_parametros)
plt.plot(x, pdf, 'r-', linewidth=2, label='Distribución Mejor Ajustada')
plt.xlabel('Taker_buy_quote_asset_volume')
plt.ylabel('Densidad de Probabilidad')
plt.title('Ajuste de Distribución a Taker_buy_quote_asset_volume')
plt.legend()
plt.show()

df_resultados

"""Distribución Exponencial"""

# Seleccionar la columna 'Taker_buy_base_asset_volume' del DataFrame
datos_taker_base = df['Taker_buy_base_asset_volume']

# Obtener los parámetros de ajuste para varias distribuciones
distribuciones = ['gamma', 'expon', 'lognorm', 'beta', 'norm']
resultados_evaluacion = []
mejor_distribucion = None
mejor_parametros = None
mejor_sse = float('inf')

for distribucion in distribuciones:
    # Ajustar la distribución a los datos
    distribucion_actual = getattr(stats, distribucion)
    parametros = distribucion_actual.fit(datos_taker_base)

    # Calcular el error cuadrático medio (SSE) para evaluar el ajuste
    sse = sum((distribucion_actual.pdf(datos_taker_base, *parametros) - datos_taker_base)**2)

    # Calcular el AIC y el BIC
    n = len(datos_taker_base)
    k = len(parametros)
    aic = n * np.log(sse / n) + 2 * k
    bic = n * np.log(sse / n) + k * np.log(n)

    resultados_evaluacion.append({
        'Distribución': distribucion,
        'SSE': sse,
        'AIC': aic,
        'BIC': bic
    })
    # Actualizar la mejor distribución si encontramos un SSE más bajo
    if sse < mejor_sse:
        mejor_distribucion = distribucion_actual
        mejor_parametros = parametros
        mejor_sse = sse

df_resultados = pd.DataFrame(resultados_evaluacion)
# Configuración del estilo de la gráfica
sns.set(style="whitegrid")

# Creación de la gráfica con histograma y distribución mejor ajustada
plt.figure(figsize=(8, 6))
sns.histplot(datos_taker_base, bins=30, kde=True, color='skyblue', label='Datos', stat='density')
x = np.linspace(datos_taker_base.min(), datos_taker_base.max(), 100)
pdf = mejor_distribucion.pdf(x, *mejor_parametros)
plt.plot(x, pdf, 'r-', linewidth=2, label='Distribución Mejor Ajustada')
plt.xlabel('Taker_buy_base_asset_volume')
plt.ylabel('Densidad de Probabilidad')
plt.title('Ajuste de Distribución a Taker_buy_base_asset_volume')
plt.legend()
plt.show()

df_resultados

"""Distribución Exponencial"""

# Seleccionar la columna 'Number_of_trades' del DataFrame
datos_number = df['Number_of_trades']

# Obtener los parámetros de ajuste para varias distribuciones
distribuciones = ['gamma', 'expon', 'lognorm', 'beta', 'norm']
resultados_evaluacion = []
mejor_distribucion = None
mejor_parametros = None
mejor_sse = float('inf')

for distribucion in distribuciones:
    # Ajustar la distribución a los datos
    distribucion_actual = getattr(stats, distribucion)
    parametros = distribucion_actual.fit(datos_number)

    # Calcular el error cuadrático medio (SSE) para evaluar el ajuste
    sse = sum((distribucion_actual.pdf(datos_number, *parametros) - datos_number)**2)

    # Calcular el AIC y el BIC
    n = len(datos_number)
    k = len(parametros)
    aic = n * np.log(sse / n) + 2 * k
    bic = n * np.log(sse / n) + k * np.log(n)

    resultados_evaluacion.append({
        'Distribución': distribucion,
        'SSE': sse,
        'AIC': aic,
        'BIC': bic
    })
    # Actualizar la mejor distribución si encontramos un SSE más bajo
    if sse < mejor_sse:
        mejor_distribucion = distribucion_actual
        mejor_parametros = parametros
        mejor_sse = sse

df_resultados = pd.DataFrame(resultados_evaluacion)
# Configuración del estilo de la gráfica
sns.set(style="whitegrid")

# Creación de la gráfica con histograma y distribución mejor ajustada
plt.figure(figsize=(8, 6))
sns.histplot(datos_number, bins=30, kde=True, color='skyblue', label='Datos', stat='density')
x = np.linspace(datos_number.min(), datos_number.max(), 100)
pdf = mejor_distribucion.pdf(x, *mejor_parametros)
plt.plot(x, pdf, 'r-', linewidth=2, label='Distribución Mejor Ajustada')
plt.xlabel('Number of Trades')
plt.ylabel('Densidad de Probabilidad')
plt.title('Ajuste de Distribución a Number of trades')
plt.legend()
plt.show()

df_resultados

"""Distribución Exponencial"""

# Seleccionar la columna 'Quote_asset_volume' del DataFrame
datos_quote = df['Quote_asset_volume']

# Obtener los parámetros de ajuste para varias distribuciones
distribuciones = ['gamma', 'expon', 'lognorm', 'beta', 'norm']
resultados_evaluacion = []
mejor_distribucion = None
mejor_parametros = None
mejor_sse = float('inf')

for distribucion in distribuciones:
    # Ajustar la distribución a los datos
    distribucion_actual = getattr(stats, distribucion)
    parametros = distribucion_actual.fit(datos_quote)

    # Calcular el error cuadrático medio (SSE) para evaluar el ajuste
    sse = sum((distribucion_actual.pdf(datos_quote, *parametros) - datos_quote)**2)

    # Calcular el AIC y el BIC
    n = len(datos_quote)
    k = len(parametros)
    aic = n * np.log(sse / n) + 2 * k
    bic = n * np.log(sse / n) + k * np.log(n)

    resultados_evaluacion.append({
        'Distribución': distribucion,
        'SSE': sse,
        'AIC': aic,
        'BIC': bic
    })
    # Actualizar la mejor distribución si encontramos un SSE más bajo
    if sse < mejor_sse:
        mejor_distribucion = distribucion_actual
        mejor_parametros = parametros
        mejor_sse = sse

df_resultados = pd.DataFrame(resultados_evaluacion)
# Configuración del estilo de la gráfica
sns.set(style="whitegrid")

# Creación de la gráfica con histograma y distribución mejor ajustada
plt.figure(figsize=(8, 6))
sns.histplot(datos_quote, bins=30, kde=True, color='skyblue', label='Datos', stat='density')
x = np.linspace(datos_quote.min(), datos_quote.max(), 100)
pdf = mejor_distribucion.pdf(x, *mejor_parametros)
plt.plot(x, pdf, 'r-', linewidth=2, label='Distribución Mejor Ajustada')
plt.xlabel('Quote asset volume')
plt.ylabel('Densidad de Probabilidad')
plt.title('Ajuste de Distribución a Quote asset volume')
plt.legend()
plt.show()

df_resultados

"""Distribución Exponencial"""

# Seleccionar la columna 'volume' del DataFrame
datos_volume = df['Volume']

# Obtener los parámetros de ajuste para varias distribuciones
distribuciones = ['gamma', 'expon', 'lognorm', 'beta', 'norm']
resultados_evaluacion = []
mejor_distribucion = None
mejor_parametros = None
mejor_sse = float('inf')

for distribucion in distribuciones:
    # Ajustar la distribución a los datos
    distribucion_actual = getattr(stats, distribucion)
    parametros = distribucion_actual.fit(datos_volume)

    # Calcular el error cuadrático medio (SSE) para evaluar el ajuste
    sse = sum((distribucion_actual.pdf(datos_volume, *parametros) - datos_volume)**2)

    # Calcular el AIC y el BIC
    n = len(datos_volume)
    k = len(parametros)
    aic = n * np.log(sse / n) + 2 * k
    bic = n * np.log(sse / n) + k * np.log(n)

    resultados_evaluacion.append({
        'Distribución': distribucion,
        'SSE': sse,
        'AIC': aic,
        'BIC': bic
    })
    # Actualizar la mejor distribución si encontramos un SSE más bajo
    if sse < mejor_sse:
        mejor_distribucion = distribucion_actual
        mejor_parametros = parametros
        mejor_sse = sse

df_resultados = pd.DataFrame(resultados_evaluacion)
# Configuración del estilo de la gráfica
sns.set(style="whitegrid")

# Creación de la gráfica con histograma y distribución mejor ajustada
plt.figure(figsize=(8, 6))
sns.histplot(datos_volume, bins=30, kde=True, color='skyblue', label='Datos', stat='density')
x = np.linspace(datos_volume.min(), datos_volume.max(), 100)
pdf = mejor_distribucion.pdf(x, *mejor_parametros)
plt.plot(x, pdf, 'r-', linewidth=2, label='Distribución Mejor Ajustada')
plt.xlabel('Volume')
plt.ylabel('Densidad de Probabilidad')
plt.title('Ajuste de Distribución a Volume')
plt.legend()
plt.show()

df_resultados

"""Distribución Exponencial

### Nuevas Características
"""

df.set_index('Open_time', inplace=True)

df.drop('Close_time', axis=1, inplace=True)

df.shape

"""### Características Lineales"""

df['co'] = df['Close'].shift(-1) - df['Open']
df['hl'] = df['High'].shift(-1) - df['Low']
df['ol'] = df['Open'].shift(-1) - df['Low']
df['ho'] = df['High'].shift(-1) - df['Open']
df['cov'] = df['co'] / df['Volume']
df['hlv'] = df['hl'] / df['Volume']

missing_values_count = df.isnull().sum()
print(missing_values_count)
np.shape(df)

df = df.dropna()

missing_values_count = df.isnull().sum()
print(missing_values_count)
np.shape(df)

df.drop('Open', axis=1, inplace=True)
df.drop('High', axis=1, inplace=True)
df.drop('Low', axis=1, inplace=True)
df.drop('Close', axis=1, inplace=True)
df.drop('Ignore', axis=1, inplace=True)

df.head()

df['co'].hist()

df['hl'].hist()

df['ol'].hist()

df['ho'].hist()

sns.boxplot(data = df[['co','hl','ol','ho']])

df.shape

"""### Características Autoregresivas"""

df['ma_ol_2'] = df['ol'].rolling(2).mean()
df['ma_ho_2'] = df['ho'].rolling(2).mean()
df['ma_hl_2'] = df['hl'].rolling(2).mean()
df['ma_hlv_2'] = df['hlv'].rolling(2).mean()
df['ma_cov_2'] = df['cov'].rolling(2).mean()

df['sd_ol_2'] = df['ol'].rolling(2).std()
df['sd_ho_2'] = df['ho'].rolling(2).std()
df['sd_hl_2'] = df['hl'].rolling(2).std()
df['sd_hlv_2'] = df['hlv'].rolling(2).std()
df['sd_cov_2'] = df['cov'].rolling(2).std()

df['lag_vol_2'] = df['Volume'].shift(2)
df['sum_vol_2'] = df['Volume'].rolling(2).sum()
df['mean_vol_2'] = df['Volume'].rolling(2).mean()

missing_values_count = df.isnull().sum()
print(missing_values_count)
np.shape(df)

df_filled = df.fillna(0)

missing_values_count = df_filled.isnull().sum()
print(missing_values_count)
np.shape(df_filled)

df_filled.head()

df['ma_ol_3'] = df['ol'].rolling(3).mean()
df['ma_ho_3'] = df['ho'].rolling(3).mean()
df['ma_hl_3'] = df['hl'].rolling(3).mean()
df['ma_hlv_3'] = df['hlv'].rolling(3).mean()
df['ma_cov_3'] = df['cov'].rolling(3).mean()

df['sd_ol_3'] = df['ol'].rolling(3).std()
df['sd_ho_3'] = df['ho'].rolling(3).std()
df['sd_hl_3'] = df['hl'].rolling(3).std()
df['sd_hlv_3'] = df['hlv'].rolling(3).std()
df['sd_cov_3'] = df['cov'].rolling(3).std()

df['lag_vol_3'] = df['Volume'].shift(3)
df['sum_vol_3'] = df['Volume'].rolling(3).sum()
df['mean_vol_3'] = df['Volume'].rolling(3).mean()

missing_values_count = df.isnull().sum()
print(missing_values_count)
np.shape(df)

df_filled = df.fillna(0)

missing_values_count = df_filled.isnull().sum()
print(missing_values_count)
np.shape(df_filled)

df.describe()

"""### Correlación"""

df_corr = df_filled
correlation_matrix = df_corr.corr()


sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
#plt.title('Matriz de Correlación')
plt.show()

"""Es evidente que algunas variables tienen alta correlación entre sí tales como:
- 'Open'
- 'High'
- 'Low'
- 'Close'

Así como también:
- 'Volume'
- 'Quote_asset_volume'
- 'Number_of_trades'
- 'Taker_buy_base_volume'
- 'Taker_buy_quote_asset_volume'

# Preprocesamiento

## Identificación de Valores Faltantes
"""

missing_values_count = df_filled.isnull().sum()
print(missing_values_count)
np.shape(df)

new_df = df_filled.copy()

new_df.shape

"""## División de Datos en Entrenamiento y Prueba"""

X = new_df.drop(['Response'], axis=1)
y = new_df['Response']

X.info()

"""## Escalado"""

X[np.isinf(X)] = 0

scaler = preprocessing.MinMaxScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled,y, test_size = 0.2,random_state = 1)

"""## Principal Component Analysis"""

X_std = StandardScaler().fit_transform(X)

cov_matrix = np.cov(X_std, rowvar=False)

pca = PCA()
principal_components = pca.fit_transform(X_std)

"""### Varianza Acumulada"""

explained_variance_ratio_cumsum = np.cumsum(pca.explained_variance_ratio_)
print("Varianza explicada por cada componente principal:", explained_variance_ratio_cumsum)

plt.figure(figsize=(10, 6))
plt.plot(range(1, len(explained_variance_ratio_cumsum)+1), explained_variance_ratio_cumsum, marker='o', linestyle='--')
#plt.title('Proporción Acumulativa de Varianza Explicada')
plt.xlabel('Número de Componentes Principales')
plt.ylabel('Proporción Acumulativa de Varianza')
plt.grid(True)
plt.show()

"""### Selección de Número de Componentes"""

n_components = 30
pca = PCA(n_components=n_components)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

"""# Modelo de Redes Neuronales

## Función del Modelo
"""

def model_nn():
  model = tf.keras.Sequential()
  model.add(Dense(25, input_dim=X_train.shape[1], activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(12, activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(1, activation='sigmoid'))
  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

"""## Modelo en Keras"""

nnmodel = KerasClassifier(model = model_nn)

"""## Espacio de Búsqueda de Hiperparámetros"""

batchSize = [10, 50, 100]
epochs = [10, 30 ,50]
parameter_grid = dict(batch_size = batchSize, epochs=epochs)

mygrid = GridSearchCV(estimator = nnmodel, param_grid = parameter_grid, n_jobs = 1, cv = 3)
grid_result = mygrid.fit(principal_components,y)

print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

def model_nn(optimizer='SGD'):
  model = tf.keras.Sequential()
  model.add(Dense(18, input_dim=X_train.shape[1], activation='relu'))
  model.add(Dropout(0.3),) #técnica de regularización, Goeff Hinto
  model.add(Dense(9, activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(1, activation='sigmoid'))
  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])
  return model

nnmodel = KerasClassifier(model = model_nn, batch_size = 50, epochs = 50)

optimizer = ['SGD','Adam', 'Adadelta']
param = dict(optimizer=optimizer)

grid1 = GridSearchCV(estimator = nnmodel, param_grid=param, n_jobs=-1, cv=3)
grid_result1 = grid1.fit(principal_components,y)

print("Best: %f using %s" % (grid_result1.best_score_, grid_result1.best_params_))

"""## Modelo Final"""

def model_nnnnn():
  model = tf.keras.Sequential()
  model.add(Dense(39, input_dim=X_train_pca.shape[1], activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(15, activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(10, activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(1, activation='sigmoid'))
  model.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy'])
  return model

nnnnnmodel = KerasClassifier(model = model_nnnnn, batch_size = 50, epochs = 50)

nnnnnmodel.fit(X_train_pca,y_train)

"""## Predicción"""

y_pred = nnnnnmodel.predict(X_test_pca)

print('Accuracy of neural network classifier on train set: {:.2f}'.format(nnnnnmodel.score(X_train_pca, y_train)))

print('Accuracy of neural network classifier on test set: {:.2f}'.format(nnnnnmodel.score(X_test_pca, y_test)))

print('Precision of neural network classifier on test set: {:.2f}'.format(precision_score(y_test, y_pred)))

"""### Métricas"""

accuracy_nn = accuracy_score(y_test, y_pred)
precision_nn = precision_score(y_test, y_pred)
recall_nn = recall_score(y_test, y_pred)
f1_score_nn = f1_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
print(accuracy_nn, precision_nn, recall_nn, f1_score_nn, conf_matrix)

y_scores = nnnnnmodel.predict_proba(X_test_pca)[:, 1]

fpr_nn, tpr_nn, thresholds_nn = roc_curve(y_test, y_scores)
auc_roc_nn = roc_auc_score(y_test, y_scores)

plt.figure(figsize=(8, 8))
plt.plot(fpr_nn, tpr_nn, color='red', lw=2, label=f'AUC = {auc_roc_nn:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

"""# Modelo Regresión Logística

## Modelo en SKLearn
"""

lrmodel = LogisticRegression()

"""## Definición de Parámetros"""

solvers = ['newton-cg','liblinear','lbfgs']
penalty = ['l2','l1', 'elasticnet']
c_values = [100, 10, 1.0, 0.1, 0.01]

"""## Espacio de Búsqueda de Hiperparámetros"""

grid = dict(solver=solvers,penalty=penalty,C=c_values)
cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)
grid_search = GridSearchCV(estimator=lrmodel, param_grid=grid, n_jobs=-1, cv=3, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(X_std, y)

print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']

"""## Modelo Final"""

logreg = LogisticRegression(solver = 'liblinear',
                            penalty='l1',
                            C=1,
                            multi_class='ovr')
logreg.fit(X_train, y_train)

"""## Predicción"""

y_pred_lr = logreg.predict(X_test)

print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(logreg.score(X_train, y_train)))

print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))

print('Precision of logistic regression classifier on test set: {:.2f}'.format(precision_score(y_test, y_pred_lr)))

"""### Métricas"""

accuracy_lr = accuracy_score(y_test, y_pred_lr)
precision_lr = precision_score(y_test, y_pred_lr)
recall_lr = recall_score(y_test, y_pred_lr)
f1_score_lr = f1_score(y_test, y_pred_lr)
conf_matrix = confusion_matrix(y_test, y_pred_lr)
print(accuracy_lr, precision_lr, recall_lr, f1_score_lr, conf_matrix)

y_scores_lr = logreg.predict_proba(X_test_pca)[:, 1]

fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_scores_lr)
auc_roc_lr = roc_auc_score(y_test, y_scores_lr)

plt.figure(figsize=(8, 8))
plt.plot(fpr_lr, tpr_lr, color='blue', lw=2, label=f'AUC = {auc_roc_lr:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

"""# Comparación de Modelos

## Tabla de Resultados
"""

resultados_final = {'Modelo': ['Neural Network','Logistic Regression'],
              'Accuracy': [accuracy_nn, accuracy_lr],
              'Precision': [precision_nn, precision_lr],
              'Recall': [recall_nn, recall_lr],
              'F1 Score': [f1_score_nn, f1_score_lr],
              'AUC-ROC': [auc_roc_nn, auc_roc_lr]}
resultados = pd.DataFrame(data=resultados_final)
print(resultados)

"""## Curvas ROC y AUC"""

plt.figure(figsize=(8, 8))
plt.plot(fpr_nn, tpr_nn, color='red', lw=2, label=f'AUC NN= {auc_roc_nn:.2f}')
plt.plot(fpr_lr, tpr_lr, color='blue', lw=2, label=f'AUC LR= {auc_roc_lr:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

"""# Reducción de Multicolinealidad bajo criterio propuesto de correlación

## Correlación
"""

df_corr = df.drop('Ignore', axis = 1)
correlation_matrix = df_corr.corr()


sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Matriz de Correlación')
plt.show()

"""Se eliminarán las siguientes variables:
- 'Open'
- 'High'
- 'Low'
- 'Quote_asset_volume'
- 'Number_of_trades'
- 'Taker_buy_base_asset_volume'
- 'Taker_buy_quote_asset_bolume'

Por la alta correlación que existe entre ellas, con el fin de eliminar la multicolinealidad y basándonos que existe una alta correlación por tener información similar. Con esto se espera simplificar el modelo, tener mayor interpretabilidad y no repetir información.

## Preprocesamiento

### División de Datos
"""

X_2 = new_df.drop(['Response','Close_time','Ignore','Open','High','Low',
                   'Quote_asset_volume','Number_of_trades',
                   'Taker_buy_base_asset_volume',
                   'Taker_buy_quote_asset_volume'], axis=1)
y_2 = new_df['Response']

X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2, y_2, test_size = 0.2,random_state = 1)

feature_names = ['Close','Volume','day_of_week','hour_of_day','month','price_diff','daily_range','buy_sell_ratio']

"""### Escalado"""

min_max_scaler = preprocessing.MinMaxScaler()
X_2_minmax = min_max_scaler.fit_transform(X_2)
X_2_train_minmax = min_max_scaler.fit_transform(X_2_train)
X_2_test_minmax = min_max_scaler.fit_transform(X_2_test)

"""# Nuevo Modelo de Redes Neuronales

## Función del Modelo
"""

def model_nn2():
  model = tf.keras.Sequential()
  model.add(Dense(16, input_dim=X_2_train_minmax.shape[1], activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(8, activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(1, activation='sigmoid'))
  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

"""## Modelo en Keras"""

nn2model = KerasClassifier(model = model_nn2)

"""## Espacio de Búsqueda de Hiperparámetros"""

batchSize = [10, 50, 100]
epochs = [10, 30 ,50]
parameter_grid2 = dict(batch_size = batchSize, epochs=epochs)

mygrid = GridSearchCV(estimator = nnmodel, param_grid = parameter_grid2, n_jobs = 1, cv = 3)
grid_result2 = mygrid.fit(X_std,y)

print("Best: %f using %s" % (grid_result2.best_score_, grid_result2.best_params_))

def model_nn2(optimizer='SGD'):
  model = tf.keras.Sequential()
  model.add(Dense(16, input_dim=X_2_train_minmax.shape[1], activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(8, activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(1, activation='sigmoid'))
  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])
  return model

nn2model = KerasClassifier(model = model_nn2, batch_size = 100, epochs = 30)

optimizer = ['SGD','Adam', 'Adadelta']
param2 = dict(optimizer=optimizer)

grid2 = GridSearchCV(estimator = nn2model, param_grid=param2, n_jobs=-1, cv=3)
grid_result3 = grid2.fit(X_std,y)

print("Best: %f using %s" % (grid_result3.best_score_, grid_result3.best_params_))

"""## Modelo Final"""

def model_nnn2():
  model = tf.keras.Sequential()
  model.add(Dense(16, input_dim=X_2_train_minmax.shape[1], activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(8, activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(1, activation='sigmoid'))
  model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])
  return model

nnn2model = KerasClassifier(model = model_nnn2, batch_size = 100, epochs = 30)

nnn2model.fit(X_2_train_minmax,y_train)

"""## Predicción"""

y_pred2 = nnn2model.predict(X_2_test_minmax)

print('Accuracy of neural network classifier on train set: {:.2f}'.format(nnn2model.score(X_2_train_minmax, y_train)))

print('Accuracy of neural network classifier on test set: {:.2f}'.format(nnn2model.score(X_2_test_minmax, y_test)))

print('Precision of neural network classifier on test set: {:.2f}'.format(precision_score(y_test, y_pred2)))

"""### Métricas"""

accuracy_nn2 = accuracy_score(y_test, y_pred2)
precision_nn2 = precision_score(y_test, y_pred2)
recall_nn2 = recall_score(y_test, y_pred2)
f1_score_nn2 = f1_score(y_test, y_pred2)
conf_matrix2 = confusion_matrix(y_test, y_pred2)
print(accuracy_nn2, precision_nn2, recall_nn2, f1_score_nn2, conf_matrix2)

y_scores2 = nnn2model.predict_proba(X_2_test_minmax)[:, 1]

fpr_nn2, tpr_nn2, thresholds_nn2 = roc_curve(y_test, y_scores2)
auc_roc_nn2 = roc_auc_score(y_test, y_scores2)

plt.figure(figsize=(8, 8))
plt.plot(fpr_nn2, tpr_nn2, color='red', lw=2, label=f'AUC = {auc_roc_nn2:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

"""# Nuevo Modelo de Regresión Logística

## Modelo en SKLearn
"""

lrmodel2 = LogisticRegression()

"""## Definición de Hiperparámetros"""

solvers = ['newton-cg','liblinear','lbfgs']
penalty = ['l2','l1', 'elasticnet']
c_values = [100, 10, 1.0, 0.1, 0.01]

"""## Espacio de Búsqueda de Hiperparámetros"""

grid2 = dict(solver=solvers,penalty=penalty,C=c_values)
cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)
grid_search2 = GridSearchCV(estimator=lrmodel, param_grid=grid2, n_jobs=-1, cv=3, scoring='accuracy',error_score=0)
grid_result2 = grid_search2.fit(X_std, y)

print("Best: %f using %s" % (grid_result2.best_score_, grid_result2.best_params_))
means = grid_result2.cv_results_['mean_test_score']
stds = grid_result2.cv_results_['std_test_score']
params = grid_result2.cv_results_['params']

"""## Modelo Final"""

logreg2 = LogisticRegression(solver = 'liblinear', penalty='l1', C=1.0)
logreg2.fit(X_2_train_minmax, y_train)

"""## Predicción"""

y_pred_lr2 = logreg2.predict(X_2_test_minmax)

print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(logreg2.score(X_2_train_minmax, y_train)))

print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg2.score(X_2_test_minmax, y_test)))

print('Precision of logistic regression classifier on test set: {:.2f}'.format(precision_score(y_test, y_pred_lr2)))

"""### Métricas"""

accuracy_lr2 = accuracy_score(y_test, y_pred_lr2)
precision_lr2 = precision_score(y_test, y_pred_lr2)
recall_lr2 = recall_score(y_test, y_pred_lr2)
f1_score_lr2 = f1_score(y_test, y_pred_lr2)
conf_matrix2 = confusion_matrix(y_test, y_pred_lr)
print(accuracy_lr2, precision_lr2, recall_lr2, f1_score_lr2, conf_matrix2)

y_scores_lr2 = logreg2.predict_proba(X_2_test_minmax)[:, 1]

fpr_lr2, tpr_lr2, thresholds_lr2 = roc_curve(y_test, y_scores_lr2)
auc_roc_lr2 = roc_auc_score(y_test, y_scores_lr2)

plt.figure(figsize=(8, 8))
plt.plot(fpr_lr2, tpr_lr2, color='blue', lw=2, label=f'AUC = {auc_roc_lr2:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

"""# Nueva Comparación de Resultados

## Nueva Tabla de Resultados
"""

resultados_final2 = {'Modelo': ['Neural Network V2','Logistic Regression V2'],
              'Accuracy': [accuracy_nn2, accuracy_lr2],
              'Precision': [precision_nn2, precision_lr2],
              'Recall': [recall_nn2, recall_lr2],
              'F1 Score': [f1_score_nn2, f1_score_lr2],
              'AUC-ROC': [auc_roc_nn2, auc_roc_lr2]}
resulta2 = pd.DataFrame(data=resultados_final2)
print(resulta2)

"""## Nuevas Curvas ROC y AUC"""

plt.figure(figsize=(8, 8))
plt.plot(fpr_nn2, tpr_nn2, color='red', lw=2, label=f'AUC NN= {auc_roc_nn2:.2f}')
plt.plot(fpr_lr2, tpr_lr2, color='blue', lw=2, label=f'AUC LR= {auc_roc_lr2:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

"""# Importancia de los Predictores

## Importancia por Permutación
"""

perm_importance = permutation_importance(nnn2model, X_2_test_minmax, y_test)

importances = perm_importance.importances_mean
std_devs = perm_importance.importances_std

feature_importance_nn = pd.DataFrame({'Feature':feature_names, 'Importance': importances, 'Std Dev': std_devs})

print(feature_importance_nn.sort_values(by='Importance', ascending=False))

df2 = pd.read_excel(ruta+"datos_klines_newtest.xlsx")

df2.columns = ['Open_time','Open','High','Low','Close',
                'Volume','Close_time','Quote_asset_volume',
                'Number_of_trades','Taker_buy_base_asset_volume',
                'Taker_buy_quote_asset_volume','Ignore','Response']

"""# MLP"""

mlp = MLPClassifier(random_state=1)

"""## Espacio de Búsqueda de Hiperparámetros"""

param_grid = {
    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],
    'activation': ['relu', 'tanh'],
    'solver': ['adam', 'sgd'],
    'alpha': [0.0001, 0.001, 0.01],
    'batch_size': [50, 100, 200],
    'learning_rate': ['constant','adaptive']
}

grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring='accuracy')

grid_search.fit(X_train, y_train)

best_model = grid_search.best_estimator_
best_params = grid_search.best_params_

y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print("Mejores hiperparámetros:", best_params)
print("Precisión en conjunto de prueba:", accuracy)

"""## Modelo Final"""

mlp = MLPClassifier(hidden_layer_sizes=(500,500),
                    activation='relu',
                    solver='adam',
                    alpha=0.0001,
                    learning_rate='constant',
                    batch_size=100,
                    early_stopping=True,
                    random_state=1)

mlp.fit(X_train, y_train)

"""## Predicción"""

y_pred = mlp.predict(X_test)

"""### Métricas"""

accuracy = accuracy_score(y_test, y_pred)
print("Precisión en conjunto de prueba:", accuracy)

accuracy_mlp = accuracy_score(y_test, y_pred)
precision_mlp = precision_score(y_test, y_pred)
recall_mlp = recall_score(y_test, y_pred)
f1_score_mlp = f1_score(y_test, y_pred)
conf_matrixmlp = confusion_matrix(y_test, y_pred)
print(accuracy_mlp, precision_mlp, recall_mlp, f1_score_mlp, conf_matrixmlp)

y_scoresmlp =mlp.predict_proba(X_test)[:, 1]
fpr_mlp, tpr_mlp, thresholdsmlp = roc_curve(y_test, y_scoresmlp)
auc_roc_mlp = roc_auc_score(y_test, y_scoresmlp)

plt.figure(figsize=(8, 8))
plt.plot(fpr_mlp, tpr_mlp, color='blue', lw=2, label=f'AUC = {auc_roc_mlp:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

"""## Análisis

"""

plt.figure(figsize=(8, 6))
plt.title("Curva de Aprendizaje del MLP")
plt.plot(mlp.loss_curve_)
plt.xlabel("Iteración")
plt.ylabel("Pérdida")
plt.grid(True)
plt.show()

alphas = [0.0001, 0.001, 0.01, 0.1, 1]
train_scores = []
test_scores = []
for alpha in alphas:
    mlp = MLPClassifier(hidden_layer_sizes=(50,50),
                    activation='tanh',
                    solver='adam',
                    alpha=alpha,
                    learning_rate='constant',
                    batch_size=100,
                    early_stopping=True,
                    random_state=1)
    mlp.fit(X_train, y_train)
    train_scores.append(mlp.score(X_train, y_train))
    test_scores.append(mlp.score(X_test, y_test))

plt.figure(figsize=(8, 6))
plt.title("Curvas de Validación del MLP (alpha)")
plt.plot(alphas, train_scores, label="Precisión de Entrenamiento")
plt.plot(alphas, test_scores, label="Precisión de Prueba")
plt.xlabel("Alpha")
plt.ylabel("Precisión")
plt.legend()
plt.xscale('log')
plt.grid(True)
plt.show()