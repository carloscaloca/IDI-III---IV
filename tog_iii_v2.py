# -*- coding: utf-8 -*-
"""TOG-III V2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16cGQG7AN-eBJ3iPF3gucYwc9u7b3G0Yh

# Montaje Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Librerías

## Instalación de Librerías
"""

!pip install scikeras

#!pip install keras==2.12.0
#!pip uninstall tensorflow
#!pip install tensorflow==2.12.0

#!pip uninstall tensorflow
#!pip install tensorflow --ignore-installed

"""## Importación de Librerías"""

import pandas as pd
import numpy as np
from datetime import datetime
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn import preprocessing
#import mglearn
#import talib
from sklearn.model_selection import train_test_split
from matplotlib.colors import ListedColormap
import matplotlib.patches as mpatches
import tensorflow as tf
#from skkeras import KerasClassifier
from scikeras.wrappers import KerasClassifier
from sklearn.model_selection import GridSearchCV
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras.constraints import MaxNorm
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import VarianceThreshold
from tensorflow.keras.utils import plot_model
from tensorflow.keras.optimizers import SGD
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, precision_score, recall_score, auc,roc_curve, roc_auc_score
from sklearn.metrics import f1_score
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.inspection import permutation_importance

"""# Datos

## Importación de Datos
"""

ruta = '/content/drive/MyDrive/TOG/IDI III/Datos/'
df = pd.read_excel(ruta+"datos_klines.xlsx")

"""Visualización de 'data'"""

df.head()

"""Agregar nombres de columnas"""

df.columns = ['Open_time','Open','High','Low','Close',
                'Volume','Close_time','Quote_asset_volume',
                'Number_of_trades','Taker_buy_base_asset_volume',
                'Taker_buy_quote_asset_volume','Ignore','Response']

"""Información de 'data'"""

df.info()

"""## Conversión 'unix'"""

df['Open_time'] = pd.to_datetime(df['Open_time'], unit='ms', origin='unix')
df['Close_time'] = pd.to_datetime(df['Close_time'], unit='ms',origin='unix')

df.head()

"""## Análisis Exploratorio

Definición de los parámetros de los gráficos
"""

plt.rcParams.update({'font.size': 11, 'figure.figsize': (16, 9)})
plt.style.use('ggplot')

"""### ¿Cómo están distribuidos los datos?"""

df.hist()

"""Con la información que se tiene hasta el momento podemos determinar lo siguiente:
- 'Open_time' y 'Close_time' se comportan de la misma manera como pudiera esperarse ya que únicamente son "timestamps"
- 'Open' y 'Close',siendo valores de precio de apertura y cierre por hora, comparten la misma figura de su distribución. Esto es debido a que el precio de Cierre en la hora t será el mismo precio que el de apertura en el tiempo t+1
- Las distribuciones de 'High' y 'Low' son bastante parecidas pero se alcanza a percibir una diferencia alrededor de los valores de 1800 en el eje x
- 3 distribuciones son bastante similares (a simple vista no se encuentran diferencias significativas) 'Number of trades', 'Taker buy base asset volume', 'taker buy quote asset volume'
- La variable 'Ignore' siempre se encuentra en los mismos valores
- La variable de respuesta (subida o bajada de precio) presenta frecuencias similares

### Simetría y Curtosis
"""

df.skew()

df.kurt()

sns.countplot(x='Response', data=df)
plt.title('Distribución de la Variable Objetivo')
plt.show()

"""Se puede visualizar variables altamente correlacionadas entre sí.

### ¿Cómo cambiaría las visualizaciones si agregaramos variables/características tomando en cuenta la fecha?

Dividiendo 'Open Time'
"""

df.set_index('Open_time', inplace = True)

"""Día de la Semana"""

df['day_of_week'] = df.index.dayofweek

"""Hora del Día"""

df['hour_of_day'] = df.index.hour

"""Mes"""

df['month'] = df.index.month

df.tail()

"""¿Qué día de la semana, hora del día y mes tiene más registros de subida de precios?"""

df_up = df[df['Response'] == 1]
df_down = df[df['Response'] == 0]

sns.countplot(x='day_of_week', data=df_up, order=df_up['day_of_week'].value_counts().index)
plt.title('Frecuencia de Días de la Semana donde el Precio Sube')
plt.xlabel('Día de la Semana')
plt.ylabel('Frecuencia')
plt.show()

sns.countplot(x='hour_of_day', data=df_up, order=df_up['hour_of_day'].value_counts().index)
plt.title('Frecuencia de Horas del Día donde el Precio Sube')
plt.xlabel('Hora del Día')
plt.ylabel('Frecuencia')
plt.show()

sns.countplot(x='month', data=df_up, order=df_up['month'].value_counts().index)
plt.title('Frecuencia de Mes del Año donde el Precio Sube')
plt.xlabel('Mes')
plt.ylabel('Frecuencia')
plt.show()

"""Se aprecia que los días 6 y 4 tienen una frecuencia de subida de precio mayor a los demás días de la semana. Las horas con mayor frecuencia de subida de precio es desde las 17 horas hasta las 23, de acuerdo con los datos utilizados. Por último, se observa que los meses que tienen mayor frecuencia de subida de precios son el mes 1 y el 6.

¿Qué día de la semana, hora del día y mes tiene menos registros de subida de precios?
"""

sns.countplot(x='day_of_week', data=df_down, order=df_down['day_of_week'].value_counts().index)
plt.title('Frecuencia de Días de la Semana donde el Precio Baja')
plt.xlabel('Día de la Semana')
plt.ylabel('Frecuencia')
plt.show()

sns.countplot(x='hour_of_day', data=df_down, order=df_down['hour_of_day'].value_counts().index)
plt.title('Frecuencia de Horas del Día donde el Precio Baja')
plt.xlabel('Hora del Día')
plt.ylabel('Frecuencia')
plt.show()

sns.countplot(x='month', data=df_down, order=df_down['month'].value_counts().index)
plt.title('Frecuencia de Horas del Día donde el Precio Baja')
plt.xlabel('Mes')
plt.ylabel('Frecuencia')
plt.show()

"""Se aprecia que los días 5 y 0 tienen una frecuencia de bajada de precio mayor a los demás días de la semana. Las horas con menor frecuencia de subida de precio es desde las 13 horas hasta las 16 y con un periodo también bajo a las 5. Por último, se observa que los meses que tienen mayor frecuencia de bajada de precios son el mes 7 y el 8.

### ¿Qué pudieramos observar si empezamos a crear nuevas características a partir de operaciones con las columnas ya existentes?

¿Pudiera impactar el rango entre el valor máximo y el mínimo dentro de una misma hora?
"""

df['daily_range'] = df['High'] - df['Low']

sns.boxplot(x='Response', y='daily_range', data=df)
plt.title('Comparación de Daily Range para Subidas y Bajadas')
plt.xlabel('Precio Sube (1) o Baja (0)')
plt.ylabel('Daily Range')
plt.show()

"""En la gráfica anterior se puede observar que los gráficos de caja son similares. No se puede observar a simple vista alguna diferencia que la que pudieramos inferir."""

df['buy_sell_ratio'] = df['Taker_buy_base_asset_volume'] / df['Taker_buy_quote_asset_volume']

sns.boxplot(x='Response', y='buy_sell_ratio', data=df)
plt.title('Comparación de Buy/Sell Ratio para Subidas y Bajadas')
plt.xlabel('Precio Sube (1) o Baja (0)')
plt.ylabel('Buy/Sell Ratio')
plt.show()

"""En la gráfica anterior se puede observar que los gráficos de caja son similares. No se puede observar a simple vista alguna diferencia que la que pudieramos inferir.

Volumen promedio
"""

win_size = 24

df['Average_Volume'] = df['Volume'].rolling(window= win_size).mean()

df['Relative_Volume'] = df['Volume'] / df['Average_Volume']

df.columns

"""### Correlación"""

df_corr = df.drop('Ignore', axis = 1)
correlation_matrix = df_corr.corr()


sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Matriz de Correlación')
plt.show()

"""Es evidente que algunas variables tienen alta correlación entre sí tales como:
- 'Open'
- 'High'
- 'Low'
- 'Close'

Así como también:
- 'Volume'
- 'Quote_asset_volume'
- 'Number_of_trades'
- 'Taker_buy_base_volume'
- 'Taker_buy_quote_asset_volume'

# Preprocesamiento

## Identificación de Valores Faltantes
"""

missing_values_count = df.isnull().sum()
print(missing_values_count)
np.shape(df)

new_df = df.dropna()

missing_values_count_2 = new_df.isnull().sum()
print(missing_values_count_2)
np.shape(new_df)

"""## División de Datos en Entrenamiento y Prueba"""

X = new_df.drop(['Response','Close_time','Ignore'], axis=1)
y = new_df['Response']

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2,random_state = 1)

X.info()

"""## Escalado"""

min_max_scaler = preprocessing.MinMaxScaler()
X_train_minmax = min_max_scaler.fit_transform(X_train)
X_test_minmax = min_max_scaler.fit_transform(X_test)

"""# Principal Component Analysis"""

X_std = StandardScaler().fit_transform(X)

cov_matrix = np.cov(X_std, rowvar=False)

pca = PCA()
principal_components = pca.fit_transform(X_std)

"""## Varianza Acumulada"""

explained_variance_ratio_cumsum = np.cumsum(pca.explained_variance_ratio_)
print("Varianza explicada por cada componente principal:", explained_variance_ratio_cumsum)

plt.figure(figsize=(10, 6))
plt.plot(range(1, len(explained_variance_ratio_cumsum)+1), explained_variance_ratio_cumsum, marker='o', linestyle='--')
plt.title('Proporción Acumulativa de Varianza Explicada')
plt.xlabel('Número de Componentes Principales')
plt.ylabel('Proporción Acumulativa de Varianza')
plt.grid(True)
plt.show()

"""## Selección de Número de Componentes"""

n_components = 8
pca = PCA(n_components=n_components)
X_train_pca = pca.fit_transform(X_train_minmax)
X_test_pca = pca.transform(X_test_minmax)

"""# Modelo de Redes Neuronales

## Función del Modelo
"""

def model_nn():
  model = tf.keras.Sequential()
  model.add(Dense(18, input_dim=X_train.shape[1], activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(9, activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(1, activation='sigmoid'))
  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

"""## Modelo en Keras"""

nnmodel = KerasClassifier(model = model_nn)

"""## Espacio de Búsqueda de Hiperparámetros"""

batchSize = [10, 50, 100]
epochs = [10, 30 ,50]
parameter_grid = dict(batch_size = batchSize, epochs=epochs)

mygrid = GridSearchCV(estimator = nnmodel, param_grid = parameter_grid, n_jobs = 1, cv = 3)
grid_result = mygrid.fit(principal_components,y)

print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

def model_nn(optimizer='SGD'):
  model = tf.keras.Sequential()
  model.add(Dense(18, input_dim=X_train.shape[1], activation='relu'))
  model.add(Dropout(0.3),) #técnica de regularización, Goeff Hinto
  model.add(Dense(9, activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(1, activation='sigmoid'))
  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])
  return model

nnmodel = KerasClassifier(model = model_nn, batch_size = 10, epochs = 50)

optimizer = ['SGD','Adam', 'Adadelta']
param = dict(optimizer=optimizer)

grid1 = GridSearchCV(estimator = nnmodel, param_grid=param, n_jobs=-1, cv=3)
grid_result1 = grid1.fit(principal_components,y)

print("Best: %f using %s" % (grid_result1.best_score_, grid_result1.best_params_))

"""## Modelo Final"""

def model_nnnnn():
  model = tf.keras.Sequential()
  model.add(Dense(18, input_dim=X_train_pca.shape[1], activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(9, activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(1, activation='sigmoid'))
  model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])
  return model

nnnnnmodel = KerasClassifier(model = model_nnnnn, batch_size = 50, epochs = 50)

nnnnnmodel.fit(X_train_pca,y_train)

"""## Predicción"""

y_pred = nnnnnmodel.predict(X_test_pca)

print('Accuracy of neural network classifier on train set: {:.2f}'.format(nnnnnmodel.score(X_train_pca, y_train)))

print('Accuracy of neural network classifier on test set: {:.2f}'.format(nnnnnmodel.score(X_test_pca, y_test)))

print('Precision of neural network classifier on test set: {:.2f}'.format(precision_score(y_test, y_pred)))

"""### Métricas"""

accuracy_nn = accuracy_score(y_test, y_pred)
precision_nn = precision_score(y_test, y_pred)
recall_nn = recall_score(y_test, y_pred)
f1_score_nn = f1_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
print(accuracy_nn, precision_nn, recall_nn, f1_score_nn, conf_matrix)

y_scores = nnnnnmodel.predict_proba(X_test_pca)[:, 1]

fpr_nn, tpr_nn, thresholds_nn = roc_curve(y_test, y_scores)
auc_roc_nn = roc_auc_score(y_test, y_scores)

plt.figure(figsize=(8, 8))
plt.plot(fpr_nn, tpr_nn, color='red', lw=2, label=f'AUC = {auc_roc_nn:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

"""# Modelo Regresión Logística

## Modelo en SKLearn
"""

lrmodel = LogisticRegression()

"""## Definición de Parámetros"""

solvers = ['newton-cg','liblinear','lbfgs']
penalty = ['l2','l1', 'elasticnet']
c_values = [100, 10, 1.0, 0.1, 0.01]

"""## Espacio de Búsqueda de Hiperparámetros"""

grid = dict(solver=solvers,penalty=penalty,C=c_values)
cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)
grid_search = GridSearchCV(estimator=lrmodel, param_grid=grid, n_jobs=-1, cv=3, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(principal_components, y)

print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']

"""## Modelo Final"""

logreg = LogisticRegression(solver = 'liblinear', penalty='l1', C=10)
logreg.fit(X_train_pca, y_train)

"""## Predicción"""

y_pred_lr = logreg.predict(X_test_pca)

print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(logreg.score(X_train_pca, y_train)))

print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test_pca, y_test)))

print('Precision of logistic regression classifier on test set: {:.2f}'.format(precision_score(y_test, y_pred_lr)))

"""### Métricas"""

accuracy_lr = accuracy_score(y_test, y_pred_lr)
precision_lr = precision_score(y_test, y_pred_lr)
recall_lr = recall_score(y_test, y_pred_lr)
f1_score_lr = f1_score(y_test, y_pred_lr)
conf_matrix = confusion_matrix(y_test, y_pred_lr)
print(accuracy_lr, precision_lr, recall_lr, f1_score_lr, conf_matrix)

y_scores_lr = logreg.predict_proba(X_test_pca)[:, 1]

fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_scores_lr)
auc_roc_lr = roc_auc_score(y_test, y_scores_lr)

plt.figure(figsize=(8, 8))
plt.plot(fpr_lr, tpr_lr, color='blue', lw=2, label=f'AUC = {auc_roc_lr:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

"""# Comparación de Modelos

## Tabla de Resultados
"""

resultados_final = {'Modelo': ['Neural Network','Logistic Regression'],
              'Accuracy': [accuracy_nn, accuracy_lr],
              'Precision': [precision_nn, precision_lr],
              'Recall': [recall_nn, recall_lr],
              'F1 Score': [f1_score_nn, f1_score_lr],
              'AUC-ROC': [auc_roc_nn, auc_roc_lr]}
resultados = pd.DataFrame(data=resultados_final)
print(resultados)

"""## Curvas ROC y AUC"""

plt.figure(figsize=(8, 8))
plt.plot(fpr_nn, tpr_nn, color='red', lw=2, label=f'AUC NN= {auc_roc_nn:.2f}')
plt.plot(fpr_lr, tpr_lr, color='blue', lw=2, label=f'AUC LR= {auc_roc_lr:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

"""# Reducción de Multicolinealidad bajo criterio propuesto de correlación

## Correlación
"""

df_corr = df.drop('Ignore', axis = 1)
correlation_matrix = df_corr.corr()


sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Matriz de Correlación')
plt.show()

"""Se eliminarán las siguientes variables:
- 'Open'
- 'High'
- 'Low'
- 'Quote_asset_volume'
- 'Number_of_trades'
- 'Taker_buy_base_asset_volume'
- 'Taker_buy_quote_asset_bolume'

Por la alta correlación que existe entre ellas, con el fin de eliminar la multicolinealidad y basándonos que existe una alta correlación por tener información similar. Con esto se espera simplificar el modelo, tener mayor interpretabilidad y no repetir información.

## Preprocesamiento

### División de Datos
"""

X_2 = new_df.drop(['Response','Close_time','Ignore','Open','High','Low',
                   'Quote_asset_volume','Number_of_trades',
                   'Taker_buy_base_asset_volume',
                   'Taker_buy_quote_asset_volume'], axis=1)
y_2 = new_df['Response']

X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2, y_2, test_size = 0.2,random_state = 1)

feature_names = ['Close','Volume','day_of_week','hour_of_day','month','price_diff','daily_range','buy_sell_ratio']

"""### Escalado"""

min_max_scaler = preprocessing.MinMaxScaler()
X_2_minmax = min_max_scaler.fit_transform(X_2)
X_2_train_minmax = min_max_scaler.fit_transform(X_2_train)
X_2_test_minmax = min_max_scaler.fit_transform(X_2_test)

"""# Nuevo Modelo de Redes Neuronales

## Función del Modelo
"""

def model_nn2():
  model = tf.keras.Sequential()
  model.add(Dense(16, input_dim=X_2_train_minmax.shape[1], activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(8, activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(1, activation='sigmoid'))
  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

"""## Modelo en Keras"""

nn2model = KerasClassifier(model = model_nn2)

"""## Espacio de Búsqueda de Hiperparámetros"""

batchSize = [10, 50, 100]
epochs = [10, 30 ,50]
parameter_grid2 = dict(batch_size = batchSize, epochs=epochs)

mygrid = GridSearchCV(estimator = nnmodel, param_grid = parameter_grid2, n_jobs = 1, cv = 3)
grid_result2 = mygrid.fit(X_std,y)

print("Best: %f using %s" % (grid_result2.best_score_, grid_result2.best_params_))

def model_nn2(optimizer='SGD'):
  model = tf.keras.Sequential()
  model.add(Dense(16, input_dim=X_2_train_minmax.shape[1], activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(8, activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(1, activation='sigmoid'))
  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])
  return model

nn2model = KerasClassifier(model = model_nn2, batch_size = 100, epochs = 30)

optimizer = ['SGD','Adam', 'Adadelta']
param2 = dict(optimizer=optimizer)

grid2 = GridSearchCV(estimator = nn2model, param_grid=param2, n_jobs=-1, cv=3)
grid_result3 = grid2.fit(X_std,y)

print("Best: %f using %s" % (grid_result3.best_score_, grid_result3.best_params_))

"""## Modelo Final"""

def model_nnn2():
  model = tf.keras.Sequential()
  model.add(Dense(16, input_dim=X_2_train_minmax.shape[1], activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(8, activation='relu'))
  model.add(Dropout(0.3),)
  model.add(Dense(1, activation='sigmoid'))
  model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])
  return model

nnn2model = KerasClassifier(model = model_nnn2, batch_size = 100, epochs = 30)

nnn2model.fit(X_2_train_minmax,y_train)

"""## Predicción"""

y_pred2 = nnn2model.predict(X_2_test_minmax)

print('Accuracy of neural network classifier on train set: {:.2f}'.format(nnn2model.score(X_2_train_minmax, y_train)))

print('Accuracy of neural network classifier on test set: {:.2f}'.format(nnn2model.score(X_2_test_minmax, y_test)))

print('Precision of neural network classifier on test set: {:.2f}'.format(precision_score(y_test, y_pred2)))

"""### Métricas"""

accuracy_nn2 = accuracy_score(y_test, y_pred2)
precision_nn2 = precision_score(y_test, y_pred2)
recall_nn2 = recall_score(y_test, y_pred2)
f1_score_nn2 = f1_score(y_test, y_pred2)
conf_matrix2 = confusion_matrix(y_test, y_pred2)
print(accuracy_nn2, precision_nn2, recall_nn2, f1_score_nn2, conf_matrix2)

y_scores2 = nnn2model.predict_proba(X_2_test_minmax)[:, 1]

fpr_nn2, tpr_nn2, thresholds_nn2 = roc_curve(y_test, y_scores2)
auc_roc_nn2 = roc_auc_score(y_test, y_scores2)

plt.figure(figsize=(8, 8))
plt.plot(fpr_nn2, tpr_nn2, color='red', lw=2, label=f'AUC = {auc_roc_nn2:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

"""# Nuevo Modelo de Regresión Logística

## Modelo en SKLearn
"""

lrmodel2 = LogisticRegression()

"""## Definición de Hiperparámetros"""

solvers = ['newton-cg','liblinear','lbfgs']
penalty = ['l2','l1', 'elasticnet']
c_values = [100, 10, 1.0, 0.1, 0.01]

"""## Espacio de Búsqueda de Hiperparámetros"""

grid2 = dict(solver=solvers,penalty=penalty,C=c_values)
cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)
grid_search2 = GridSearchCV(estimator=lrmodel, param_grid=grid2, n_jobs=-1, cv=3, scoring='accuracy',error_score=0)
grid_result2 = grid_search2.fit(X_std, y)

print("Best: %f using %s" % (grid_result2.best_score_, grid_result2.best_params_))
means = grid_result2.cv_results_['mean_test_score']
stds = grid_result2.cv_results_['std_test_score']
params = grid_result2.cv_results_['params']

"""## Modelo Final"""

logreg2 = LogisticRegression(solver = 'liblinear', penalty='l1', C=1.0)
logreg2.fit(X_2_train_minmax, y_train)

"""## Predicción"""

y_pred_lr2 = logreg2.predict(X_2_test_minmax)

print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(logreg2.score(X_2_train_minmax, y_train)))

print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg2.score(X_2_test_minmax, y_test)))

print('Precision of logistic regression classifier on test set: {:.2f}'.format(precision_score(y_test, y_pred_lr2)))

"""### Métricas"""

accuracy_lr2 = accuracy_score(y_test, y_pred_lr2)
precision_lr2 = precision_score(y_test, y_pred_lr2)
recall_lr2 = recall_score(y_test, y_pred_lr2)
f1_score_lr2 = f1_score(y_test, y_pred_lr2)
conf_matrix2 = confusion_matrix(y_test, y_pred_lr)
print(accuracy_lr2, precision_lr2, recall_lr2, f1_score_lr2, conf_matrix2)

y_scores_lr2 = logreg2.predict_proba(X_2_test_minmax)[:, 1]

fpr_lr2, tpr_lr2, thresholds_lr2 = roc_curve(y_test, y_scores_lr2)
auc_roc_lr2 = roc_auc_score(y_test, y_scores_lr2)

plt.figure(figsize=(8, 8))
plt.plot(fpr_lr2, tpr_lr2, color='blue', lw=2, label=f'AUC = {auc_roc_lr2:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

"""# Nueva Comparación de Resultados

## Nueva Tabla de Resultados
"""

resultados_final2 = {'Modelo': ['Neural Network V2','Logistic Regression V2'],
              'Accuracy': [accuracy_nn2, accuracy_lr2],
              'Precision': [precision_nn2, precision_lr2],
              'Recall': [recall_nn2, recall_lr2],
              'F1 Score': [f1_score_nn2, f1_score_lr2],
              'AUC-ROC': [auc_roc_nn2, auc_roc_lr2]}
resulta2 = pd.DataFrame(data=resultados_final2)
print(resulta2)

"""## Nuevas Curvas ROC y AUC"""

plt.figure(figsize=(8, 8))
plt.plot(fpr_nn2, tpr_nn2, color='red', lw=2, label=f'AUC NN= {auc_roc_nn2:.2f}')
plt.plot(fpr_lr2, tpr_lr2, color='blue', lw=2, label=f'AUC LR= {auc_roc_lr2:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

"""# Importancia de los Predictores

## Importancia por Permutación
"""

perm_importance = permutation_importance(nnn2model, X_2_test_minmax, y_test)

importances = perm_importance.importances_mean
std_devs = perm_importance.importances_std

feature_importance_nn = pd.DataFrame({'Feature':feature_names, 'Importance': importances, 'Std Dev': std_devs})

print(feature_importance_nn.sort_values(by='Importance', ascending=False))

"""# Importación de Nuevos Datos"""

df2 = pd.read_excel(ruta+"datos_klines_newtest.xlsx")

df2.columns = ['Open_time','Open','High','Low','Close',
                'Volume','Close_time','Quote_asset_volume',
                'Number_of_trades','Taker_buy_base_asset_volume',
                'Taker_buy_quote_asset_volume','Ignore','Response']

"""# Conversión Unix"""

df2['Open_time'] = pd.to_datetime(df2['Open_time'], unit='ms', origin='unix')
df2['Close_time'] = pd.to_datetime(df2['Close_time'], unit='ms',origin='unix')

"""# Características"""

df2.set_index('Open_time', inplace = True)

df2['day_of_week'] = df2.index.dayofweek

df2['hour_of_day'] = df2.index.hour

df2['month'] = df2.index.month

df2['daily_range'] = df2['High'] - df2['Low']

df2['buy_sell_ratio'] = df2['Taker_buy_base_asset_volume'] / df2['Taker_buy_quote_asset_volume']

df2['price_diff'] = df2['Close'].diff()

"""# Preprocesamiento"""

missing_values_count2 = df2.isnull().sum()
print(missing_values_count2)
np.shape(df2)

new_df2 = df2.dropna()

X2 = new_df2.drop(['Response','Close_time','Ignore'], axis=1)
y2 = new_df2['Response']

"""# Escalado"""

X_newstd = StandardScaler().fit_transform(X2)

"""# PCA"""

X_newstd_pca = pca.fit_transform(X_newstd)

"""# Nueva Predicción"""

y_newpred = nnnnnmodel.predict(X_newstd_pca)

accuracy_nn3 = accuracy_score(y2, y_newpred)
precision_nn3 = precision_score(y2, y_newpred)
recall_nn3 = recall_score(y2, y_newpred)
f1_score_nn3 = f1_score(y2, y_newpred)
conf_matrix3 = confusion_matrix(y2, y_newpred)
print(accuracy_nn3, precision_nn3, recall_nn3, f1_score_nn3, conf_matrix3)

y_scores2 = nnnnnmodel.predict_proba(X_newstd_pca)[:, 1]

fpr_nn3, tpr_nn3, thresholds_nn3 = roc_curve(y2, y_scores2)
auc_roc_nn3 = roc_auc_score(y2, y_scores2)

plt.figure(figsize=(8, 8))
plt.plot(fpr_nn3, tpr_nn3, color='red', lw=2, label=f'AUC = {auc_roc_nn3:.2f}')
plt.plot([0, 1], [0, 1], color='green', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()